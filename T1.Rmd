---
title: "Trabalho 1 - Aprendizado de Máquina"
output: html_notebook
---

```{r}
library(data.tree)

computeEntropy <- function(data, attIndex=NULL, classIndex) {
    #classes no problema 
    classes <- unique(data[,classIndex])
    
    #se attIndex nao for informado, calcula a entropia (Info(D)) para o conjunto de dados inteiro
    if (is.null(attIndex)) {
        #a priori entropy
        
        entropy<-0
        for (ii in 1:length(classes)){
            temp<- length(which(data[[classIndex]] == classes[ii]))
            prob <- temp/dim(data)[1]
            entropy <- entropy + (-(prob*log2(prob)))
        }
    } else{
        #caso contrário, calcula a entropia restrita a um subconjunto de dados 
        # (após particao por valor 'v' do atributo 'A')
        if(is.numeric(data[, attIndex]))
        {
          values <- 2
          entropy <- 0

          temp1 <- length(which(data[,attIndex] > mean(data[,attIndex])))
          prob1 <- temp1/dim(data)[1]
          data.subset <- data[which(data[,attIndex] > mean(data[,attIndex])),]
          soma <- 0
          for(ii in 1:length(classes)){
            temp <- length(which(data.subset[,classIndex] == classes[ii]))
            if(temp > 0){
              prob <- temp/dim(data.subset)[1]
              soma <- soma+(-(prob*log2(prob)))
            }else{
              soma <- soma+0
            }
          }
          entropy <- entropy + (prob1*soma)
          
          temp1 <- length(which(data[,attIndex] <= mean(data[,attIndex])))
          prob1 <- temp1/dim(data)[1]
          data.subset <- data[which(data[,attIndex] <= mean(data[,attIndex])),]
          soma <- 0
          for(ii in 1:length(classes)){
            temp <- length(which(data.subset[,classIndex] == classes[ii]))
            if(temp > 0){
              prob <- temp/dim(data.subset)[1]
              soma <- soma+(-(prob*log2(prob)))
            }else{
              soma <- soma+0
            }
          }
          entropy <- entropy + (prob1*soma)
        }
        else{
          values<- unique(data[,attIndex])
          entropy<-0
          for (jj in 1:length(values)) {
              temp1 <- length(which(data[,attIndex] ==values[jj])) 
              prob1 <- temp1/dim(data)[1]
              data.subset <- data[which(data[,attIndex] ==values[jj]),]
              soma<-0
              for (ii in 1:length(classes)){
                  temp<- length(which(data.subset[,classIndex]==classes[ii]))
                  if(temp > 0){
                      prob <- temp/dim(data.subset)[1]
                      soma <- soma+(-(prob*log2(prob)))
                  }else{
                      soma <- soma+0
                  }
              }
              entropy <- entropy + (prob1*soma)
          }
        }
    }
  entropy
    }  
```

```{r}
randomAttr <- function(data){
  colId <- sample(1:ncol(data), round(sqrt(ncol(data))), replace=FALSE)
  #print(colId)
  return(colId)
}
```

```{r}
computeTree <- function(tree, data, indexClass){
  randomAtt <- randomAttr(data[-indexClass])
  entropyClass <- computeEntropy(data, NULL, indexClass)
  entropies <- numeric(ncol(data)-1)
  for(i in 1:length(randomAtt)){
    entropies[randomAtt[i]] <- entropyClass - computeEntropy(data, attIndex = randomAtt[i], indexClass)
  }
  maxGain <- which.max(entropies)
  if(!is.numeric(data[[maxGain]])){
    test <- unique(data[maxGain])
    entropies <- NULL
    entropies <- numeric(nrow(test))
  }

  subData <- list()

  tree  <- tree$AddChild(colnames(data[maxGain]))
  
  if(is.numeric(data[[maxGain]])){
    for(i in 1:2){
      if(i == 1){
        child <- tree$AddChild(paste("<=", mean(data[,maxGain])))
        subData[[i]] <- data[which(data[,maxGain] <= mean(data[,maxGain])),]
      } 
      else { 
        child <- tree$AddChild(paste(">", mean(data[,maxGain]))) 
        subData[[i]] <- data[which(data[,maxGain] > mean(data[,maxGain])),]

        }
    if(length(unique(subData[[i]][,indexClass])) > 1){
      child <- computeTree(child, subData[[i]], indexClass)
    } 
    else if(length(unique(subData[[i]][,indexClass]))){

      #print(length(unique(subData[[i]][,indexClass])))
      child$AddChild(unique(subData[[i]][,indexClass]))
    }
    }
  }
  else{
    for(i in 1:(nrow(test))){
      child <- tree$AddChild(test[[1]][i])
      subData[[i]] <- data[which(data[[maxGain]]==test[[1]][i]),]
      if(length(unique(subData[[i]][,indexClass])) > 1){
        subData[[i]] <- computeTree(child, subData[[i]], indexClass)
      } else if(length(unique(subData[[i]][,indexClass])) > 0){
        #print(length(unique(subData[[i]][,indexClass])))
        child$AddChild(unique(subData[[i]][,indexClass]))
      }
    }
  }
  return(tree)
}
```

```{r}
walkTree <- function(tree, testData){
  if(isLeaf(tree)){
    return(tree$name)
    }
    else{
  attribute <- grep(tree$name, colnames(testData))
  if(is.numeric(testData[[attribute]])){
    attAvg <- substring(tree$children[[1]]$name, 4)
    if(testData[[attribute]] > as.numeric(attAvg)){
      walkTree(tree$children[[2]]$children[[1]], testData)
    } else {
      walkTree(tree$children[[1]]$children[[1]], testData)
    }
  } 
  else {
    for(i in 1:tree$count){
      if(identical(testData[[attribute]],tree$children[[i]]$name)){
        return(walkTree(tree$children[[i]]$children[[1]], testData))
      }
    }
  }
    }

}
```

```{r}
bootstraping <- function(data, indexClass){
  bsId <- sample(1:nrow(data), nrow(data), replace=TRUE)
  trainData <- data[bsId,]
  
  tree <- Node$new("ROOT")
  tree <- computeTree(tree, trainData, indexClass)
  
  return(tree)
}
```

```{r}
ensemble <- function(data, indexClass, nTrees){
  randomTrees <- list()
  for(i in 1:nTrees){
    randomTrees[[i]] <- bootstraping(data, indexClass)
  }
  return(randomTrees)
}
```

```{r}
voter <- function(ensembleL, testData){
  result <- vector()
  for(i in 1:length(ensembleL)){
    if(length(walkTree(ensembleL[[i]], testData)) != 0){
      result[i] <- walkTree(ensembleL[[i]], testData)
    }
  }
  return(sort(result, decreasing=TRUE)[1])
}

```

```{r}
computeAcc <- function(ensembleL, testData, classIndex){
  acc <- 0
  for(i in 1:nrow(testData)){
    if(testData[i,classIndex] == voter(ensembleL, testData[i,])){
      acc <- acc+1
    }
  }
  return(acc/nrow(testData))
}
```

```{r}
#data <- read.csv("dadosBenchmark.csv",header = TRUE,stringsAsFactors = FALSE,sep=";")
#data <- read.csv("pima.csv", header = TRUE, stringsAsFactors = FALSE, sep = "\t")
#data$target <- as.logical(data$target)
#indexClass <- 5

 data2 <- read.csv("pimateste.csv", header = TRUE, stringsAsFactors = FALSE, sep = "\t")
 data2$target <- as.logical(data2$target)
 indexClass <- 9
 #data$RID <- NULL

 classOne <- data2[which(data2$target == TRUE),]
 classTwo <- data2[which(data2$target == FALSE),]
 
 randomClassOne <- classOne[sample(nrow(classOne), round(0.2*nrow(classOne))),]
 randomClassTwo <- classTwo[sample(nrow(classTwo), round(0.2*nrow(classTwo))),]
 test <- rbind(randomClassOne, randomClassTwo)
 
 accuracy <- vector()
 
 for(i in 1:50){
  nTrees <- i
  randomTrees <- list()
  randomTrees <- ensemble(data2, indexClass, nTrees)
  accuracy[i] <- computeAcc(randomTrees, test, indexClass)
 }
```